{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "from matplotlib.ticker import FormatStrFormatter  \n",
    "sns.set(font_scale=2)\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from scipy.stats import pearsonr\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = ['ETTm1','ETTm2','ETTh1','ETTh2','Exchange','Weather', 'Traffic', 'Electricity','ILI', 'Solar Hour', 'Solar 10min', 'River Flow', 'Sunspot']\n",
    "datasets = ['ettm1','ettm2','etth1','etth2','exchange_ltsf','weather_ltsf','illness_ltsf','sunspot', 'solar_hour', 'solar_10min','river_flow']\n",
    "def replace_dataset_name(df):\n",
    "    df['dataset'] = df['dataset'].replace('ettm1', 'ETTm1', regex=True) \n",
    "    df['dataset'] = df['dataset'].replace('ettm2', 'ETTm2', regex=True) \n",
    "    df['dataset'] = df['dataset'].replace('etth1', 'ETTh1', regex=True) \n",
    "    df['dataset'] = df['dataset'].replace('etth2', 'ETTh2', regex=True) \n",
    "    df['dataset'] = df['dataset'].replace('exchange_ltsf', 'Exchange', regex=True) \n",
    "    df['dataset'] = df['dataset'].replace('weather_ltsf', 'Weather', regex=True) \n",
    "    df['dataset'] = df['dataset'].replace('traffic_ltsf', 'Traffic', regex=True) \n",
    "    df['dataset'] = df['dataset'].replace('electricity_ltsf', 'Electricity', regex=True) \n",
    "    df['dataset'] = df['dataset'].replace('illness_ltsf', 'ILI', regex=True) \n",
    "    df['dataset'] = df['dataset'].replace('solar_hour', 'Solar Hour', regex=True) \n",
    "    df['dataset'] = df['dataset'].replace('solar_10min', 'Solar 10min', regex=True) \n",
    "    df['dataset'] = df['dataset'].replace('river_flow', 'River Flow', regex=True) \n",
    "    df['dataset'] = df['dataset'].replace('sunspot', 'Sunspot', regex=True) \n",
    "    return df\n",
    "\n",
    "def sort_order(cat_res, sort_order_dict=None, inf_sort_order=False):\n",
    "    # cat_res = cat_res.loc[cat_res['Infer hor.'] != '24']\n",
    "    \n",
    "    # inf_sort_order = ['48', '60', '96', '192', '336', '720', '1024']\n",
    "    if inf_sort_order:\n",
    "        inf_sort_order = ['24', '48', '96', '192','336', '720', '1024']\n",
    "        cat_res['Infer hor.'] = pd.Categorical(cat_res['Infer hor.'], categories=inf_sort_order, ordered=True)\n",
    "        cat_res = cat_res.sort_values(by='Infer hor.')\n",
    "    \n",
    "    if sort_order_dict is not None:\n",
    "        for key, value in sort_order_dict.items():\n",
    "            cat_res[key] = pd.Categorical(cat_res[key], categories=value, ordered=True)\n",
    "            cat_res = cat_res.sort_values(by=key)\n",
    "    \n",
    "    return cat_res\n",
    "\n",
    "def filed_filter(df, fileds_dict, eq=True):\n",
    "    for key, values in fileds_dict.items():\n",
    "        if eq:\n",
    "            df = df[df[key].isin(values)]\n",
    "        else:\n",
    "            df = df[~df[key].isin(values)]\n",
    "                \n",
    "    return df\n",
    "\n",
    "def add_spec_setting(res_dict, prefix=''):\n",
    "    datasets = []\n",
    "    infer_hor = []\n",
    "    train_hor = []\n",
    "    val_hor = []\n",
    "    ND = []\n",
    "    NRMSE = []\n",
    "    seed = []\n",
    "    for dataset in ['ETTm1','ETTm2','ETTh1','ETTh2','Exchange','Weather', 'Electricity','Traffic', 'Solar Hour', 'Solar 10min', 'River Flow', 'Sunspot']:\n",
    "        for hor in ['96', '192', '336', '720']:\n",
    "            try: \n",
    "                ND.append(res_dict[(res_dict['val_len']==hor) & (res_dict['Infer hor.']==hor) & (res_dict['Train hor.']==hor) & (res_dict['dataset']==dataset)]['ND'].values[0])\n",
    "                NRMSE.append(res_dict[(res_dict['val_len']==hor) & (res_dict['Infer hor.']==hor) & (res_dict['Train hor.']==hor) & (res_dict['dataset']==dataset)]['NRMSE'].values[0])\n",
    "                datasets.append(dataset)\n",
    "                infer_hor.append(hor)\n",
    "                train_hor.append(prefix+'spec')\n",
    "                val_hor.append(prefix+'spec')\n",
    "                seed.append(0)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    res_dict = {\"dataset\": datasets, \"Infer hor.\": infer_hor, \"Train hor.\": train_hor, \"val_len\": val_hor, \"ND\": ND , \"NRMSE\": NRMSE, \"seeds\": seed,}\n",
    "    return pd.DataFrame(res_dict)\n",
    "\n",
    "def plot_multi_marked_line(res,  x,  y, hue=None, style=None, title=None, datasets=['ETTh1'],save_name=None,line_styles=False, \n",
    "                           line_style_list=None,errorbar=None, palette=None, data_char=None, axvline=None,axhline=None, axhline_label=None,\n",
    "                           hight=5, width=6, x_min=None, x_max=None, all_in_one=False, font_scale=1.5):\n",
    "    sns.set(font_scale=font_scale)\n",
    "    sub_num = len(datasets)\n",
    "    if palette:\n",
    "        sns.set_palette(palette)\n",
    "    if sub_num > 1 and not all_in_one:\n",
    "        plt.figure()\n",
    "        total_len = sub_num * width\n",
    "        fig, ax = plt.subplots(1, sub_num,figsize=(total_len, hight))  \n",
    "        legend = False\n",
    "        for i in range(sub_num):\n",
    "            if line_style_list is not None:\n",
    "                local_line_style = line_style_list[i]\n",
    "            else:\n",
    "                local_line_style = line_styles\n",
    "                \n",
    "            if datasets[i] == 'ETT':\n",
    "                sub_res = res[(res['dataset']=='ETTm1') | (res['dataset']=='ETTm2') | (res['dataset']=='ETTh1') | (res['dataset']=='ETTh2')]\n",
    "            else:\n",
    "                sub_res = res[res['dataset']==datasets[i]]\n",
    "                \n",
    "            if i == (sub_num-1):\n",
    "                legend = True\n",
    "            sns.lineplot(\n",
    "                data=sub_res, legend=legend,\n",
    "                x=x, y=y, hue=hue, style=style, ax=ax[i], errorbar=errorbar,\n",
    "                markers=True, dashes=local_line_style, linewidth=2,markersize=10\n",
    "            )\n",
    "            if axvline is not None:\n",
    "                ax[i].axvline(x=axvline, color='r', linestyle='--', linewidth=2,markersize=10) \n",
    "            ax[i].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            \n",
    "            if data_char is not None:\n",
    "                season = data_char[datasets[i]]['Seasonality']\n",
    "                trend = data_char[datasets[i]]['Trend']\n",
    "                data_char_str = f'\\nFs:{season} Ft:{trend}'\n",
    "            else:\n",
    "                data_char_str = ''\n",
    "            ax[i].set_title(f'{datasets[i]}{data_char_str}')  \n",
    "            ax[i].tick_params(axis='y', labelsize=15)    \n",
    "            ax[i].tick_params(axis='x', labelsize=16)    \n",
    "            if i > 0:\n",
    "                ax[i].set_ylabel('')\n",
    "                \n",
    "        if title is not None:\n",
    "            fig.suptitle(title)\n",
    "    else:\n",
    "        plt.figure(figsize=(width, hight))\n",
    "        if datasets[0] == 'ETT':\n",
    "            sub_res = res[(res['dataset']=='ETTm1') | (res['dataset']=='ETTm2') | (res['dataset']=='ETTh1') | (res['dataset']=='ETTh2')]\n",
    "        else:\n",
    "            # sub_res = res[res['dataset']==datasets[0]]\n",
    "            sub_res = res[res['dataset'].isin(datasets)]\n",
    "        sns.lineplot(\n",
    "            data=sub_res,\n",
    "            x=x, \n",
    "            y=y, \n",
    "            hue=hue, style=style, errorbar=None,\n",
    "            markers=True, dashes=line_styles, linewidth=2, markersize=10\n",
    "        )\n",
    "        if axvline is not None:\n",
    "            plt.axvline(x=axvline, color='r', linestyle='--', linewidth=2,markersize=10) \n",
    "            \n",
    "        if axhline is not None:\n",
    "            plt.axhline(y=axhline, color='gray', linestyle='--', linewidth=2, label=axhline_label)\n",
    "        \n",
    "        if x_min is not None:\n",
    "            plt.xlim(x_min, x_max)\n",
    "            \n",
    "        if title is not None:\n",
    "            plt.title(title)\n",
    "    \n",
    "    # plt.legend(title=hue, loc='upper left', bbox_to_anchor=(1, 1))  \n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1),title=hue)  \n",
    "    plt.tight_layout() \n",
    "    if save_name is not None:\n",
    "        plt.savefig(f'fig/{save_name}.svg', format='svg') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_result(root_dir, verbose=True, models=['PatchTST'], train_pred_len_list=['96', '192', '336', '720'], train_context_list=['96'], datasets=None):\n",
    "    NRMSE = []\n",
    "    ND = []\n",
    "    CRPS = []\n",
    "    train_pred_len_lists = []\n",
    "    dataset_list = []\n",
    "    seeds = []\n",
    "    train_ctx = []\n",
    "    model_list = []\n",
    "    if datasets is None:\n",
    "        datasets = ['ettm1','ettm2','etth1','etth2','exchange_ltsf','weather_ltsf','electricity_ltsf','traffic_ltsf','illness_ltsf']\n",
    "\n",
    "    seed=0\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        for model in models:\n",
    "            for train_pred_len in train_pred_len_list:\n",
    "                for train_context in train_context_list:\n",
    "                    csv_file = root_dir + f\"{dataset}_{train_context}_{train_pred_len}_{model}_{seed}/test/metrics.csv\"\n",
    "                    try:\n",
    "                        data = pd.read_csv(csv_file)\n",
    "                    except:\n",
    "                        if verbose:\n",
    "                            print(\"cannot find \", csv_file) \n",
    "                        continue\n",
    "                    \n",
    "                    for idx in range(len(data)):\n",
    "                        NRMSE.append(data['test_NRMSE'][idx])\n",
    "                        ND.append(data['test_ND'][idx])\n",
    "                        CRPS.append(data['test_CRPS'][idx])\n",
    "\n",
    "                        dataset_list.append(dataset)\n",
    "                        model_str = model\n",
    "                        train_pred_len_lists.append(train_pred_len)\n",
    "                        train_ctx.append(train_context)\n",
    "                        model_list.append(model_str)\n",
    "                        seeds.append(seed)\n",
    "\n",
    "    res_dict = {\"dataset\": dataset_list, \"pred hor.\": train_pred_len_lists, \"ND\":ND , \"NRMSE\": NRMSE, 'CRPS':CRPS, \"seeds\": seeds,\n",
    "                \"model\": model_list,'train_ctx': train_ctx}\n",
    "\n",
    "    return pd.DataFrame(res_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReVIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PatchTST\n",
    "\n",
    "datasets=None\n",
    "root_dir = \"/data/Blob_WestJP/v-jiawezhang/log/abl_revin/norm_false/logs/\"\n",
    "# norm_false_res = load_result(root_dir=root_dir, verbose=False, models=['GRU_NVP', 'PatchTST'], datasets=datasets) \n",
    "norm_false_res = load_result(root_dir=root_dir, verbose=False, models=['PatchTST'], datasets=datasets) \n",
    "# norm_false_res['norm'] = 'None'\n",
    "norm_false_res['scaling'] = 'false'\n",
    "norm_false_res['revin'] = 'false'\n",
    "\n",
    "root_dir = \"/data/Blob_WestJP/v-jiawezhang/log/abl_revin/norm_true/logs/\"\n",
    "norm_true_res = load_result(root_dir=root_dir, verbose=False, models=['PatchTST'], datasets=datasets) \n",
    "# norm_true_res['norm'] = 'ReVIN'\n",
    "norm_true_res['scaling'] = 'false'\n",
    "norm_true_res['revin'] = 'true'\n",
    "\n",
    "root_dir = \"/data/Blob_WestJP/v-jiawezhang/log/abl_revin/norm_temp/logs/\"\n",
    "norm_temp_res = load_result(root_dir=root_dir, verbose=False, models=['PatchTST'], datasets=datasets) \n",
    "# norm_temp_res['norm'] = 'Scaling'\n",
    "norm_temp_res['scaling'] = 'true'\n",
    "norm_temp_res['revin'] = 'false'\n",
    "\n",
    "patchtst_res= pd.concat([norm_false_res, norm_true_res, norm_temp_res], ignore_index=True)\n",
    "patchtst_res['scaler'] = 'standard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_results(root_path, models):\n",
    "    combined_df = pd.DataFrame()\n",
    "    datasets = ['etth1','exchange_ltsf','weather_ltsf','traffic_ltsf','electricity_ltsf']\n",
    "    for scaler in ['identity', 'standard']:\n",
    "        for revin in ['true', 'false']:\n",
    "            for scaling in ['false', 'true']:\n",
    "                norm_res = load_result(root_dir = f\"{root_path}{scaler}_revin_{revin}_scaling_{scaling}/logs/\", verbose=False, models=models, datasets=datasets)\n",
    "                norm_res['scaler'] = scaler\n",
    "                norm_res['revin'] = revin\n",
    "                norm_res['scaling'] = scaling\n",
    "                combined_df = pd.concat([combined_df, norm_res], ignore_index=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_nvp_res = get_df_results('/data/Blob_WestJP/v-jiawezhang/log/abl_norm/', ['GRU_NVP'])\n",
    "csdi_res = get_df_results('/data/Blob_EastUS/v-jiawezhang/log/abl_norm/', ['CSDI'])\n",
    "timegrad_res = get_df_results('/data/Blob_EastUS/v-jiawezhang/log/abl_norm/', ['TimeGrad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([patchtst_res, gru_nvp_res, csdi_res, timegrad_res], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(res_dict):\n",
    "    datasets = []\n",
    "    pred_hor = []\n",
    "    norm = []\n",
    "    ND = []\n",
    "    CRPS = []\n",
    "    seed = []\n",
    "    global_norm = []\n",
    "    model = []\n",
    "    for index, row in res_dict.iterrows():\n",
    "        if row['revin'] == 'true' and row['scaling'] == 'false':\n",
    "            norm.append('ReVIN')\n",
    "        elif row['revin'] == 'false' and row['scaling'] == 'true':\n",
    "            norm.append('Scaling')\n",
    "        elif row['revin'] == 'false' and row['scaling'] == 'false':\n",
    "            norm.append('None')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        datasets.append(row['dataset'])\n",
    "        pred_hor.append(row['pred hor.'])\n",
    "        ND.append(row['ND'])\n",
    "        global_norm.append(row['scaler'])\n",
    "        CRPS.append(row['CRPS'])\n",
    "        model.append(row['model'])\n",
    "        \n",
    "            \n",
    "    res_dict = {'model': model, \"dataset\": datasets, \"gobal norm\": global_norm, \"pred hor.\": pred_hor, \"CRPS\": CRPS, \"ND\": ND , \"norm\": norm}\n",
    "    return pd.DataFrame(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_res = reformat(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_res = replace_dataset_name(norm_res)\n",
    "\n",
    "sort_order_dict = {'pred hor.': ['96','192','336','720'], 'model': ['PatchTST', 'CSDI','TimeGrad', 'GRU_NVP'], 'norm': ['ReVIN', 'Scaling','None']}\n",
    "sort_norm_res = sort_order(norm_res, sort_order_dict=sort_order_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_norm_res['CRPS/ND'] = sort_norm_res.apply(lambda x: f\"{x['CRPS']:.3f}/{x['ND']:.3f}\", axis=1)\n",
    "sort_norm_res['ND'] = sort_norm_res.apply(lambda x: f\"{x['ND']:.4f}\", axis=1)\n",
    "sort_norm_res['CRPS'] = sort_norm_res.apply(lambda x: f\"{x['CRPS']:.4f}\", axis=1)\n",
    "\n",
    "sort_norm_res = sort_norm_res[sort_norm_res[\"gobal norm\"]=='standard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table\n",
    "pivot_table = pd.pivot_table(\n",
    "    sort_norm_res,\n",
    "    values=['ND'],\n",
    "    index=['dataset', 'pred hor.'],\n",
    "    columns=['model', 'norm'],\n",
    "    aggfunc=lambda x: x.iloc[0],\n",
    "    observed=False\n",
    ")\n",
    "pivot_table.columns = ['_'.join(col).strip() for col in pivot_table.columns.values]\n",
    "pivot_table = pivot_table.reset_index()\n",
    "pivot_table_formatted_md = pivot_table.to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | dataset     |   pred hor. |   ND_PatchTST_ReVIN |   ND_PatchTST_Scaling |   ND_PatchTST_None |   ND_CSDI_ReVIN |   ND_CSDI_Scaling |   ND_CSDI_None |   ND_TimeGrad_ReVIN |   ND_TimeGrad_Scaling |   ND_TimeGrad_None |   ND_GRU_NVP_ReVIN |   ND_GRU_NVP_Scaling |   ND_GRU_NVP_None |\n",
      "|---:|:------------|------------:|--------------------:|----------------------:|-------------------:|----------------:|------------------:|---------------:|--------------------:|----------------------:|-------------------:|-------------------:|---------------------:|------------------:|\n",
      "|  0 | ETTh1       |          96 |              0.3212 |                0.3437 |             0.3447 |          0.3643 |            0.4605 |         0.4718 |              0.3783 |                0.8983 |             0.7105 |             0.3569 |               0.776  |            0.5452 |\n",
      "|  1 | ETTh1       |         192 |              0.3562 |                0.3943 |             0.3785 |          0.4445 |            0.5683 |         0.5839 |              0.3926 |                0.8034 |             0.7218 |             0.3946 |               0.5698 |            0.6226 |\n",
      "|  2 | ETTh1       |         336 |              0.3737 |                0.4213 |             0.4099 |          0.4524 |            0.5321 |         0.6081 |              0.4942 |                0.8381 |             0.7928 |             0.3933 |               0.7277 |            0.5773 |\n",
      "|  3 | ETTh1       |         720 |              0.3909 |                0.4881 |             0.4648 |          0.5118 |            0.5351 |         0.7027 |              0.4332 |                1.0233 |             0.7552 |             0.4409 |               0.9122 |            0.7305 |\n",
      "|  4 | Electricity |          96 |              0.0857 |                0.0867 |             0.0848 |          0.0975 |            0.091  |         0.0924 |            nan      |              nan      |           nan      |             0.1007 |               0.1133 |            0.1141 |\n",
      "|  5 | Electricity |         192 |              0.0912 |                0.0918 |             0.091  |        nan      |            0.338  |         0.3218 |            nan      |              nan      |           nan      |             0.1044 |               0.1231 |            0.117  |\n",
      "|  6 | Electricity |         336 |              0.1001 |                0.1005 |             0.1006 |        nan      |            0.3689 |         0.4213 |            nan      |              nan      |           nan      |             0.1174 |               0.1208 |            0.1225 |\n",
      "|  7 | Electricity |         720 |              0.116  |                0.1187 |             0.1178 |        nan      |            0.3873 |         0.3726 |            nan      |              nan      |           nan      |           nan      |             nan      |          nan      |\n",
      "|  8 | Exchange    |          96 |              0.0235 |                0.0254 |             0.0299 |          0.0275 |            0.0272 |         0.0444 |              0.032  |                0.0617 |             0.092  |             0.0282 |               0.0662 |            0.078  |\n",
      "|  9 | Exchange    |         192 |              0.0336 |                0.0365 |             0.0404 |          0.0475 |            0.0465 |         0.0545 |              0.0403 |                0.0909 |             0.0714 |             0.0382 |               0.1117 |            0.1097 |\n",
      "| 10 | Exchange    |         336 |              0.0462 |                0.0532 |             0.0597 |          0.0654 |            0.0543 |         0.0671 |              0.0554 |                0.1392 |             0.1117 |             0.0526 |               0.1252 |            0.0834 |\n",
      "| 11 | Exchange    |         720 |              0.0777 |                0.081  |             0.0824 |          0.1112 |            0.1198 |         0.1223 |              0.0833 |                0.1809 |             0.1328 |             0.0722 |               0.1648 |            0.0891 |\n",
      "| 12 | Traffic     |          96 |              0.2553 |                0.2546 |             0.2526 |        nan      |          nan      |       nan      |              0.2791 |                0.2414 |             0.2436 |             0.2517 |               0.2647 |            0.2422 |\n",
      "| 13 | Traffic     |         192 |              0.2479 |                0.2447 |             0.2483 |        nan      |          nan      |       nan      |              0.2521 |                0.2461 |             0.2432 |             0.2623 |               0.2534 |            0.2484 |\n",
      "| 14 | Traffic     |         336 |              0.2492 |                0.247  |             0.2489 |        nan      |          nan      |       nan      |              0.2739 |                0.2471 |             0.2672 |             0.2772 |               0.2691 |            0.2472 |\n",
      "| 15 | Traffic     |         720 |              0.2572 |                0.2568 |             0.2577 |        nan      |          nan      |       nan      |            nan      |              nan      |           nan      |             0.3142 |               0.2815 |            0.2742 |\n",
      "| 16 | Weather     |          96 |              0.0837 |                0.1082 |             0.1051 |          0.128  |            0.071  |         0.0746 |              0.0891 |                0.2877 |             0.3731 |             0.1045 |               0.2055 |            0.1225 |\n",
      "| 17 | Weather     |         192 |              0.0858 |                0.1171 |             0.1136 |          0.2102 |            0.0857 |         0.0891 |              0.0938 |                0.3222 |             0.3787 |             0.1069 |               0.1706 |            0.1493 |\n",
      "| 18 | Weather     |         336 |              0.0903 |                0.1167 |             0.1118 |          0.5821 |            0.1023 |         0.1143 |              0.1041 |                0.3432 |             0.2737 |             0.103  |               0.2285 |            0.1367 |\n",
      "| 19 | Weather     |         720 |              0.0953 |                0.1234 |             0.1117 |          0.2316 |            0.1739 |         0.1167 |              0.1162 |                0.2637 |             0.254  |             0.1075 |               0.1458 |            0.248  |\n"
     ]
    }
   ],
   "source": [
    "print(pivot_table_formatted_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=['electricity_nips', 'solar_nips', 'exchange_rate_nips','traffic_nips', 'wiki2000_nips']\n",
    "train_pred_len_list = ['24', '30']\n",
    "train_context_list = ['24', '30']\n",
    "root_dir = \"/data/Blob_WestJP/v-jiawezhang/log/abl_revin/norm_false/logs/\"\n",
    "norm_false_res = load_result(root_dir=root_dir, verbose=False, models=['GRU_NVP', 'PatchTST'], datasets=datasets, train_pred_len_list=train_pred_len_list, train_context_list=train_context_list) \n",
    "norm_false_res['norm'] = 'None'\n",
    "\n",
    "root_dir = \"/data/Blob_WestJP/v-jiawezhang/log/abl_revin/norm_true/logs/\"\n",
    "norm_true_res = load_result(root_dir=root_dir, verbose=False, models=['GRU_NVP', 'PatchTST'], datasets=datasets, train_pred_len_list=train_pred_len_list, train_context_list=train_context_list) \n",
    "norm_true_res['norm'] = 'ReVIN'\n",
    "\n",
    "root_dir = \"/data/Blob_WestJP/v-jiawezhang/log/abl_revin/norm_temp/logs/\"\n",
    "norm_temp_res = load_result(root_dir=root_dir, verbose=False, models=['GRU_NVP', 'PatchTST'], datasets=datasets, train_pred_len_list=train_pred_len_list, train_context_list=train_context_list) \n",
    "norm_temp_res['norm'] = 'Scaling'\n",
    "\n",
    "norm_res= pd.concat([norm_false_res, norm_true_res, norm_temp_res], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame()\n",
    "datasets=['electricity_nips', 'solar_nips', 'exchange_rate_nips','traffic_nips', 'wiki2000_nips']\n",
    "train_pred_len_list = ['24', '30']\n",
    "train_context_list = ['24', '30']\n",
    "for scaler in ['identity', 'standard']:\n",
    "    for revin in ['true', 'false']:\n",
    "        for scaling in ['false', 'true']:\n",
    "            norm_res = load_result(root_dir = f\"/data/Blob_WestJP/v-jiawezhang/log/abl_norm/{scaler}_revin_{revin}_scaling_{scaling}/logs/\", verbose=False, models=['CSDI'], datasets=datasets, train_pred_len_list=train_pred_len_list, train_context_list=train_context_list) \n",
    "            norm_res['scaler'] = scaler\n",
    "            norm_res['revin'] = revin\n",
    "            norm_res['scaling'] = scaling\n",
    "            combined_df = pd.concat([combined_df, norm_res], ignore_index=True)\n",
    "            \n",
    "combined_df = reformat(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_res = replace_dataset_name(combined_df)\n",
    "norm_res['ND'] = norm_res.apply(lambda x: f\"{x['ND']:.4f}\", axis=1)\n",
    "norm_res['CRPS'] = norm_res.apply(lambda x: f\"{x['CRPS']:.4f}\", axis=1)\n",
    "sort_norm_res = sort_norm_res[sort_norm_res[\"gobal norm\"]=='identity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = pd.pivot_table(\n",
    "    norm_res,\n",
    "    values=['ND'],\n",
    "    index=['dataset'],\n",
    "    # columns=['model', 'norm'],\n",
    "    columns=['norm'],\n",
    "    aggfunc=lambda x: x.iloc[0]\n",
    ")\n",
    "pivot_table.columns = ['_'.join(col).strip() for col in pivot_table.columns.values]\n",
    "pivot_table = pivot_table.reset_index()\n",
    "pivot_table_formatted_md = pivot_table.to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | dataset            |   ND_None |   ND_ReVIN |   ND_Scaling |\n",
      "|---:|:-------------------|----------:|-----------:|-------------:|\n",
      "|  0 | electricity_nips   |  nan      |   nan      |       0.0657 |\n",
      "|  1 | exchange_rate_nips |    0.0099 |     0.0109 |       0.0109 |\n",
      "|  2 | solar_nips         |    1      |     0.5847 |       0.5832 |\n",
      "|  3 | traffic_nips       |  nan      |     0.1731 |       0.1806 |\n"
     ]
    }
   ],
   "source": [
    "print(pivot_table_formatted_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=None\n",
    "root_dir = \"/data/Blob_WestJP/v-jiawezhang/log/abl_channel/ch_dep_false/logs/\"\n",
    "indep_res = load_result(root_dir=root_dir, verbose=False, models=['DLinear', 'PatchTST'], datasets=datasets) \n",
    "indep_res['channel'] = 'indep'\n",
    "\n",
    "root_dir = \"/data/Blob_WestJP/v-jiawezhang/log/abl_channel/ch_dep_true/logs/\"\n",
    "dep_res = load_result(root_dir=root_dir, verbose=False, models=['DLinear', 'PatchTST'], datasets=datasets) \n",
    "dep_res['channel'] = 'dep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennel_res= pd.concat([dep_res,indep_res], ignore_index=True)\n",
    "chennel_res = replace_dataset_name(chennel_res)\n",
    "sort_order_dict = {'pred hor.': ['96','192','336','720']}\n",
    "sort_chennel_res = sort_order(chennel_res, sort_order_dict=sort_order_dict)\n",
    "\n",
    "sort_chennel_res['ND'] = sort_chennel_res.apply(lambda x: f\"{x['ND']:.4f}\", axis=1)\n",
    "sort_chennel_res['CRPS'] = sort_chennel_res.apply(lambda x: f\"{x['CRPS']:.4f}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3845555/372056143.py:2: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  pivot_table = pd.pivot_table(\n"
     ]
    }
   ],
   "source": [
    "# Create a pivot table\n",
    "pivot_table = pd.pivot_table(\n",
    "    sort_chennel_res,\n",
    "    values=['CRPS'],\n",
    "    index=['dataset', 'pred hor.'],\n",
    "    columns=['model', 'channel'],\n",
    "    aggfunc=lambda x: x.iloc[0]\n",
    ")\n",
    "pivot_table.columns = ['_'.join(col).strip() for col in pivot_table.columns.values]\n",
    "pivot_table = pivot_table.reset_index()\n",
    "pivot_table_formatted_md = pivot_table.to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | dataset     |   pred hor. |   CRPS_DLinear_dep |   CRPS_DLinear_indep |   CRPS_PatchTST_dep |   CRPS_PatchTST_indep |\n",
      "|---:|:------------|------------:|-------------------:|---------------------:|--------------------:|----------------------:|\n",
      "|  0 | ETTh1       |          96 |             0.3334 |               0.329  |              0.3239 |                0.3212 |\n",
      "|  1 | ETTh1       |         192 |             0.3611 |               0.4096 |              0.3609 |                0.3562 |\n",
      "|  2 | ETTh1       |         336 |             0.3918 |               0.4177 |              0.3763 |                0.3737 |\n",
      "|  3 | ETTh1       |         720 |             0.4266 |               0.4674 |              0.3882 |                0.3909 |\n",
      "|  4 | ETTh2       |          96 |             0.3127 |               0.2034 |              0.1731 |                0.1746 |\n",
      "|  5 | ETTh2       |         192 |             0.3351 |               0.2701 |              0.2001 |                0.2011 |\n",
      "|  6 | ETTh2       |         336 |             0.344  |               0.2617 |              0.2265 |                0.2244 |\n",
      "|  7 | ETTh2       |         720 |             0.4242 |               0.3009 |              0.2371 |                0.2293 |\n",
      "|  8 | ETTm1       |          96 |             0.2662 |               0.28   |              0.2652 |                0.2739 |\n",
      "|  9 | ETTm1       |         192 |             0.2914 |               0.3084 |              0.2926 |                0.2961 |\n",
      "| 10 | ETTm1       |         336 |             0.318  |               0.3302 |              0.3101 |                0.3188 |\n",
      "| 11 | ETTm1       |         720 |             0.3508 |               0.3723 |              0.345  |                0.3463 |\n",
      "| 12 | ETTm2       |          96 |             0.1485 |               0.1438 |              0.1341 |                0.1342 |\n",
      "| 13 | ETTm2       |         192 |             0.1771 |               0.1645 |              0.1623 |                0.1612 |\n",
      "| 14 | ETTm2       |         336 |             0.2127 |               0.1933 |              0.1792 |                0.1802 |\n",
      "| 15 | ETTm2       |         720 |             0.2537 |               0.2184 |              0.2068 |                0.2111 |\n",
      "| 16 | Electricity |          96 |             0.0881 |               0.0889 |              0.0832 |                0.0857 |\n",
      "| 17 | Electricity |         192 |             0.096  |               0.0939 |              0.0899 |                0.0912 |\n",
      "| 18 | Electricity |         336 |             0.102  |               0.1037 |              0.0995 |                0.1001 |\n",
      "| 19 | Electricity |         720 |             0.1234 |               0.1228 |              0.1183 |                0.116  |\n",
      "| 20 | Exchange    |          96 |             0.0248 |               0.0235 |              0.0243 |                0.0235 |\n",
      "| 21 | Exchange    |         192 |             0.0334 |               0.0326 |              0.0348 |                0.0336 |\n",
      "| 22 | Exchange    |         336 |             0.0443 |               0.0454 |              0.0471 |                0.0462 |\n",
      "| 23 | Exchange    |         720 |             0.0741 |               0.0712 |              0.0787 |                0.0777 |\n",
      "| 24 | Weather     |          96 |             0.1443 |               0.1119 |              0.0872 |                0.0837 |\n",
      "| 25 | Weather     |         192 |             0.1533 |               0.1212 |              0.0924 |                0.0858 |\n",
      "| 26 | Weather     |         336 |             0.1568 |               0.1328 |              0.0934 |                0.0903 |\n",
      "| 27 | Weather     |         720 |             0.1597 |               0.1453 |              0.0993 |                0.0953 |\n"
     ]
    }
   ],
   "source": [
    "print(pivot_table_formatted_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=['electricity_nips', 'solar_nips', 'exchange_rate_nips','traffic_nips','wiki2000_nips']\n",
    "train_pred_len_list = ['24', '30']\n",
    "train_context_list = ['24', '30']\n",
    "\n",
    "root_dir = \"/data/Blob_WestJP/v-jiawezhang/log/abl_channel/ch_dep_false/logs/\"\n",
    "indep_res = load_result(root_dir=root_dir, verbose=False, models=['DLinear', 'PatchTST'], datasets=datasets) \n",
    "indep_res['channel'] = 'indep'\n",
    "\n",
    "root_dir = \"/data/Blob_WestJP/v-jiawezhang/log/abl_channel/ch_dep_true/logs/\"\n",
    "dep_res = load_result(root_dir=root_dir, verbose=False, models=['DLinear', 'PatchTST'], datasets=datasets) \n",
    "dep_res['channel'] = 'dep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennel_res= pd.concat([dep_res,indep_res], ignore_index=True)\n",
    "chennel_res = replace_dataset_name(chennel_res)\n",
    "\n",
    "sort_chennel_res['ND'] = sort_chennel_res.apply(lambda x: f\"{x['ND']:.4f}\", axis=1)\n",
    "sort_chennel_res['CRPS'] = sort_chennel_res.apply(lambda x: f\"{x['CRPS']:.4f}\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing baselines - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_len_list=['96', '192', '336', '720', '24','36','48','60']\n",
    "train_context_list=['96', '36']\n",
    "\n",
    "datasets=['ettm1','etth1','exchange_ltsf','electricity_ltsf','traffic_ltsf','illness_ltsf']\n",
    "root_dir = \"/data/Blob_WestJP/v-jiawezhang/log/nn_baseline/logs/\"\n",
    "gru_res1 = load_result(root_dir=root_dir, verbose=False, models=['GRUForecaster'], datasets=datasets, train_pred_len_list=train_pred_len_list, train_context_list=train_context_list) \n",
    "gru_res1 = replace_dataset_name(gru_res1)\n",
    "\n",
    "datasets=['ettm2','etth2','weather_ltsf']\n",
    "root_dir = \"/data/Blob_WestJP/v-jiawezhang/log/nn_baseline_scale/logs/\"\n",
    "gru_res2 = load_result(root_dir=root_dir, verbose=False, models=['GRUForecaster'], datasets=datasets, train_pred_len_list=train_pred_len_list, train_context_list=train_context_list) \n",
    "gru_res2 = replace_dataset_name(gru_res2)\n",
    "\n",
    "gru_res = pd.concat([gru_res1, gru_res2], ignore_index=True)\n",
    "\n",
    "long_crps = pd.read_csv(\"./exp_res/long_crps.csv\")\n",
    "long_nmae = pd.read_csv(\"./exp_res/long_nmae.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res = gru_res.rename(columns={'dataset': 'Model', 'pred hor.': 'pred_len'})\n",
    "new_res['pred_len'] = new_res['pred_len'].astype(str)\n",
    "\n",
    "new_res['ND'] = new_res.apply(lambda x: f\"{x['ND']:.4f}\", axis=1)\n",
    "new_res['CRPS'] = new_res.apply(lambda x: f\"{x['CRPS']:.4f}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_nmae = long_nmae.copy()\n",
    "df_merged_nmae['pred_len'] = df_merged_nmae['pred_len'].astype(str)\n",
    "\n",
    "df_merged_crps = long_crps.copy()\n",
    "df_merged_crps['pred_len'] = df_merged_crps['pred_len'].astype(str)\n",
    "\n",
    "\n",
    "df_merged_crps = df_merged_crps.set_index(['Model', 'pred_len'])\n",
    "df_merged_nmae = df_merged_nmae.set_index(['Model', 'pred_len'])\n",
    "new_res = new_res.set_index(['Model', 'pred_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_nmae_res = pd.merge(df_merged_nmae, new_res['ND'], left_index=True, right_index=True)\n",
    "combine_nmae_res = combine_nmae_res.rename(columns={'ND': 'GRU'}).reset_index()\n",
    "\n",
    "combine_crps_res = pd.merge(df_merged_crps, new_res['CRPS'], left_index=True, right_index=True)\n",
    "combine_crps_res = combine_crps_res.rename(columns={'CRPS': 'GRU'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_nmae_res.to_csv(\"./exp_res/update_long_nmae.csv\", index=False)\n",
    "combine_crps_res.to_csv(\"./exp_res/update_long_crps.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_summary(root_dir, verbose=True, models=['ElasTST'], train_pred_len_list=['96-192-336-720'],train_context_list=['96'],datasets=None):\n",
    "    dataset_list = []\n",
    "    param_list = []\n",
    "    mem_list = []\n",
    "    train_time_list = []\n",
    "    model_list = []\n",
    "    if datasets is None:\n",
    "        datasets = ['ettm1','ettm2','etth1','etth2','exchange_ltsf','weather_ltsf','electricity_ltsf','traffic_ltsf','illness_ltsf']\n",
    "\n",
    "    seed=0\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        for model in models:\n",
    "            for train_pred_len in train_pred_len_list:\n",
    "                for train_context in train_context_list:\n",
    "                    json_file = root_dir + f\"{dataset}_{train_context}_{train_pred_len}_{model}_{seed}/summary.json\"\n",
    "                    \n",
    "                    try:\n",
    "                        with open(json_file, 'r') as file:\n",
    "                            data = json.load(file)\n",
    "                    except:\n",
    "                        if verbose:\n",
    "                            print(\"cannot find \", json_file) \n",
    "                        continue\n",
    "                    \n",
    "                    train_time = data['mean_train_batch_time']\n",
    "                    trainable_parameters = data['trainable_parameters']\n",
    "                    trainable_parameters_in_mb = trainable_parameters * 4 / (1024 ** 2)\n",
    "                    train_mem_peak = data['memory_summary']['train']['mem_peak']\n",
    "                    \n",
    "                    dataset_list.append(dataset)\n",
    "                    param_list.append(trainable_parameters_in_mb)\n",
    "                    mem_list.append(train_mem_peak)\n",
    "                    train_time_list.append(train_time)\n",
    "                    model_list.append(model)\n",
    "\n",
    "\n",
    "\n",
    "    res_dict = {\"model\":model_list, \"dataset\": dataset_list, 'NPARAMS (MB)': param_list, 'Max GPU Mem. (GB)': mem_list, \"Avg. Train Time\": train_time_list}\n",
    "\n",
    "    return pd.DataFrame(res_dict)\n",
    "\n",
    "def gpu_dataframe_to_markdown(df, filed='Max GPU Mem. (GB)'):\n",
    "    # df.loc[:,'model'] = df['model'].replace('TransformerForecaster', 'Transformer', regex=True) \n",
    "    df.loc[:, filed] = df[filed].round(4)\n",
    "    # df = df.pivot_table(index=['dataset'], columns='model', values=filed).reset_index()\n",
    "    df = df.pivot_table(index=['dataset'], columns='model', values=filed, observed=False).reset_index()\n",
    "    return df.to_markdown(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find  /data/Blob_WestJP/v-jiawezhang/log/comp_budget/logs/electricity_ltsf_96_96_DLinear_0/summary.json\n",
      "cannot find  /data/Blob_WestJP/v-jiawezhang/log/comp_budget/logs/weather_ltsf_96_96_CSDI_0/summary.json\n",
      "cannot find  /data/Blob_WestJP/v-jiawezhang/log/comp_budget/logs/traffic_ltsf_96_96_CSDI_0/summary.json\n"
     ]
    }
   ],
   "source": [
    "pred_len_list = ['96']\n",
    "datasets = ['ettm1','electricity_ltsf', 'exchange_ltsf','weather_ltsf','traffic_ltsf']\n",
    "root_dir = f\"/data/Blob_WestJP/v-jiawezhang/log/comp_budget/logs/\"\n",
    "comp_budget = load_summary(root_dir, verbose=True, models=['PatchTST','DLinear','TimeGrad','GRU_NVP','CSDI'], train_pred_len_list=pred_len_list, datasets=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>NPARAMS (MB)</th>\n",
       "      <th>Max GPU Mem. (GB)</th>\n",
       "      <th>Avg. Train Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PatchTST</td>\n",
       "      <td>ettm1</td>\n",
       "      <td>5.141750</td>\n",
       "      <td>0.032442</td>\n",
       "      <td>0.029116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DLinear</td>\n",
       "      <td>ettm1</td>\n",
       "      <td>0.497341</td>\n",
       "      <td>0.018391</td>\n",
       "      <td>0.016629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TimeGrad</td>\n",
       "      <td>ettm1</td>\n",
       "      <td>1.133266</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>0.039893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU_NVP</td>\n",
       "      <td>ettm1</td>\n",
       "      <td>1.008083</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.032739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSDI</td>\n",
       "      <td>ettm1</td>\n",
       "      <td>1.640350</td>\n",
       "      <td>0.147443</td>\n",
       "      <td>0.046746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PatchTST</td>\n",
       "      <td>electricity_ltsf</td>\n",
       "      <td>2.047001</td>\n",
       "      <td>0.047467</td>\n",
       "      <td>0.024961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TimeGrad</td>\n",
       "      <td>electricity_ltsf</td>\n",
       "      <td>3.310772</td>\n",
       "      <td>0.231849</td>\n",
       "      <td>0.036542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GRU_NVP</td>\n",
       "      <td>electricity_ltsf</td>\n",
       "      <td>3.509815</td>\n",
       "      <td>0.140491</td>\n",
       "      <td>0.021862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CSDI</td>\n",
       "      <td>electricity_ltsf</td>\n",
       "      <td>1.306679</td>\n",
       "      <td>0.286550</td>\n",
       "      <td>0.050155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PatchTST</td>\n",
       "      <td>exchange_ltsf</td>\n",
       "      <td>0.630341</td>\n",
       "      <td>0.018975</td>\n",
       "      <td>0.029638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DLinear</td>\n",
       "      <td>exchange_ltsf</td>\n",
       "      <td>0.568390</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.017065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TimeGrad</td>\n",
       "      <td>exchange_ltsf</td>\n",
       "      <td>0.464893</td>\n",
       "      <td>0.026349</td>\n",
       "      <td>0.038665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GRU_NVP</td>\n",
       "      <td>exchange_ltsf</td>\n",
       "      <td>1.886169</td>\n",
       "      <td>0.027424</td>\n",
       "      <td>0.024448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CSDI</td>\n",
       "      <td>exchange_ltsf</td>\n",
       "      <td>1.640415</td>\n",
       "      <td>0.147669</td>\n",
       "      <td>0.048242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PatchTST</td>\n",
       "      <td>weather_ltsf</td>\n",
       "      <td>2.045856</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>0.025941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DLinear</td>\n",
       "      <td>weather_ltsf</td>\n",
       "      <td>0.071125</td>\n",
       "      <td>0.016230</td>\n",
       "      <td>0.009432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TimeGrad</td>\n",
       "      <td>weather_ltsf</td>\n",
       "      <td>0.484921</td>\n",
       "      <td>0.150025</td>\n",
       "      <td>0.042694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GRU_NVP</td>\n",
       "      <td>weather_ltsf</td>\n",
       "      <td>2.879658</td>\n",
       "      <td>0.032871</td>\n",
       "      <td>0.035379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PatchTST</td>\n",
       "      <td>traffic_ltsf</td>\n",
       "      <td>2.049065</td>\n",
       "      <td>0.087063</td>\n",
       "      <td>0.025923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DLinear</td>\n",
       "      <td>traffic_ltsf</td>\n",
       "      <td>0.074333</td>\n",
       "      <td>0.024122</td>\n",
       "      <td>0.010007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TimeGrad</td>\n",
       "      <td>traffic_ltsf</td>\n",
       "      <td>7.913933</td>\n",
       "      <td>0.376532</td>\n",
       "      <td>0.036676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GRU_NVP</td>\n",
       "      <td>traffic_ltsf</td>\n",
       "      <td>15.188499</td>\n",
       "      <td>0.362345</td>\n",
       "      <td>0.035823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model           dataset  NPARAMS (MB)  Max GPU Mem. (GB)  Avg. Train Time\n",
       "0   PatchTST             ettm1      5.141750           0.032442         0.029116\n",
       "1    DLinear             ettm1      0.497341           0.018391         0.016629\n",
       "2   TimeGrad             ettm1      1.133266           0.028333         0.039893\n",
       "3    GRU_NVP             ettm1      1.008083           0.025000         0.032739\n",
       "4       CSDI             ettm1      1.640350           0.147443         0.046746\n",
       "5   PatchTST  electricity_ltsf      2.047001           0.047467         0.024961\n",
       "6   TimeGrad  electricity_ltsf      3.310772           0.231849         0.036542\n",
       "7    GRU_NVP  electricity_ltsf      3.509815           0.140491         0.021862\n",
       "8       CSDI  electricity_ltsf      1.306679           0.286550         0.050155\n",
       "9   PatchTST     exchange_ltsf      0.630341           0.018975         0.029638\n",
       "10   DLinear     exchange_ltsf      0.568390           0.018600         0.017065\n",
       "11  TimeGrad     exchange_ltsf      0.464893           0.026349         0.038665\n",
       "12   GRU_NVP     exchange_ltsf      1.886169           0.027424         0.024448\n",
       "13      CSDI     exchange_ltsf      1.640415           0.147669         0.048242\n",
       "14  PatchTST      weather_ltsf      2.045856           0.024308         0.025941\n",
       "15   DLinear      weather_ltsf      0.071125           0.016230         0.009432\n",
       "16  TimeGrad      weather_ltsf      0.484921           0.150025         0.042694\n",
       "17   GRU_NVP      weather_ltsf      2.879658           0.032871         0.035379\n",
       "18  PatchTST      traffic_ltsf      2.049065           0.087063         0.025923\n",
       "19   DLinear      traffic_ltsf      0.074333           0.024122         0.010007\n",
       "20  TimeGrad      traffic_ltsf      7.913933           0.376532         0.036676\n",
       "21   GRU_NVP      traffic_ltsf     15.188499           0.362345         0.035823"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_df = replace_dataset_name(combined_gpu_df)\n",
    "gpu_markdown = gpu_dataframe_to_markdown(comp_budget, filed='Avg. Train Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| dataset          |     CSDI |   DLinear |   GRU_NVP |   PatchTST |   TimeGrad |\n",
      "|:-----------------|---------:|----------:|----------:|-----------:|-----------:|\n",
      "| electricity_ltsf |   0.0502 |  nan      |    0.0219 |     0.025  |     0.0365 |\n",
      "| ettm1            |   0.0467 |    0.0166 |    0.0327 |     0.0291 |     0.0399 |\n",
      "| exchange_ltsf    |   0.0482 |    0.0171 |    0.0244 |     0.0296 |     0.0387 |\n",
      "| traffic_ltsf     | nan      |    0.01   |    0.0358 |     0.0259 |     0.0367 |\n",
      "| weather_ltsf     | nan      |    0.0094 |    0.0354 |     0.0259 |     0.0427 |\n"
     ]
    }
   ],
   "source": [
    "print(gpu_markdown)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
